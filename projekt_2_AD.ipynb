{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "projekt 2 AD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zywia/AD-projekt-2-/blob/additional_data/projekt_2_AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JYhOUId3ZC0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f0618938-9baf-4460-a5e1-7808158f4615"
      },
      "source": [
        "!pip install bert-for-tf2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/5c/6439134ecd17b33fe0396fb0b7d6ce3c5a120c42a4516ba0e9a2d6e43b25/bert-for-tf2-0.14.4.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 3.0MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-cp36-none-any.whl size=30114 sha256=b72e964b4d035600421b1ff46753598177a307532bc9ca06ee8e7f3981592902\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/3f/4d/79d7735015a5f523648df90d871ce8e89a7df8185f7703eeab\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=3014ef12485bac6f7b36aa8d3300cab4ab0791689a590939b99bca3836803a16\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=66ea93647093ed26891511238cbe59279650ee682c0221da348816764f02c28d\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgwbew2JMJCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ced34a70-6637-4248-a02f-efd6e8e4ed80"
      },
      "source": [
        "!pip install tf-models-nightly"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-models-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/8d/ecd0a476e192b1ac5bf469951f30b4f41b9464cbde608c6eb4effa8a9e6b/tf_models_nightly-2.2.0.dev20200707-py2.py3-none-any.whl (855kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (1.18.5)\n",
            "Collecting tf-slim>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=4.1.2 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (4.1.3)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/e4/a98a3c3098ea55b6ae193a1cd19a221dc3c1bde87a36db5550addc879d36/opencv_python_headless-4.3.0.36-cp36-cp36m-manylinux2014_x86_64.whl (36.4MB)\n",
            "\u001b[K     |████████████████████████████████| 36.4MB 71kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (1.0.5)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (0.8.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (0.7)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (0.8.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (3.2.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (2.1.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (0.29.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (1.12.0)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (1.21.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (1.7.12)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (3.6.6)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (7.0.0)\n",
            "Collecting tensorflow-model-optimization>=0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7e/e94aa029999ec30951e8129fa992fecbbaffda66eba97c65d5a83f8ea96d/tensorflow_model_optimization-0.3.0-py2.py3-none-any.whl (165kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 40.2MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (0.3.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (1.4.1)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (5.4.8)\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/5d/d954f8fbaa7aabcc90b7b437c98b3e927459b720ae4acd1cdaa3a71c8576/tf_nightly-2.4.0.dev20200706-cp36-cp36m-manylinux2010_x86_64.whl (322.9MB)\n",
            "\u001b[K     |████████████████████████████████| 322.9MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (3.13)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-nightly) (1.5.6)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim>=1.1.0->tf-models-nightly) (0.9.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-nightly) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-nightly) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-nightly) (4.6)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-nightly) (0.17.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->tf-models-nightly) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->tf-models-nightly) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.6.0->tf-models-nightly) (3.10.0)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-nightly) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-nightly) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-nightly) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-nightly) (1.2.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (2.23.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (19.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (1.12.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (0.22.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (0.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-nightly) (4.41.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-nightly) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-nightly) (0.4.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-nightly) (0.0.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-nightly) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-nightly) (1.17.2)\n",
            "Collecting dm-tree~=0.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/48/10fb721334810081b7e6eebeba0d12e12126c76993e8c243062d2f56a89f/dm_tree-0.1.5-cp36-cp36m-manylinux1_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->tf-models-nightly) (2.3.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tf-models-nightly) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tf-models-nightly) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tf-models-nightly) (3.2.1)\n",
            "Collecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/3c/985ff11fb5b886b7e9acb9781380af7735e0eebf92424ebfb05a1aade546/tf_estimator_nightly-2.4.0.dev2020070601-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tf-models-nightly) (1.30.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tf-models-nightly) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tf-models-nightly) (1.6.3)\n",
            "Collecting tb-nightly<2.4.0a0,>=2.3.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/4a/946de5d29d432f1b09bfeafb2de16fc812d374d3e32aa194d2c899fe87a1/tb_nightly-2.3.0a20200706-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tf-models-nightly) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tf-models-nightly) (0.34.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-nightly) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-nightly) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-nightly) (2020.6.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.6.0->tf-models-nightly) (47.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->tf-models-nightly) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->tf-models-nightly) (3.0.4)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-nightly) (1.52.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-nightly) (1.16.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-nightly) (4.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->tf-models-nightly) (1.0.8)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->tf-models-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->tf-models-nightly) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->tf-models-nightly) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->tf-models-nightly) (1.6.0.post3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-nightly) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->tf-models-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->tf-models-nightly) (1.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->tf-models-nightly) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->tf-models-nightly) (3.1.0)\n",
            "Building wheels for collected packages: py-cpuinfo, seqeval\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20069 sha256=7ba6a13aec1ef6e04ab8e830c31ba797000428522cb35c55664013cae395d173\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=ce0d887198e9970affd9a53941f7a329cb4c09bbcbdc1e0d94cb2d2df931ef0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built py-cpuinfo seqeval\n",
            "Installing collected packages: tf-slim, opencv-python-headless, py-cpuinfo, sentencepiece, dm-tree, tensorflow-model-optimization, seqeval, tf-estimator-nightly, tb-nightly, tf-nightly, tf-models-nightly\n",
            "Successfully installed dm-tree-0.1.5 opencv-python-headless-4.3.0.36 py-cpuinfo-7.0.0 sentencepiece-0.1.91 seqeval-0.0.12 tb-nightly-2.3.0a20200706 tensorflow-model-optimization-0.3.0 tf-estimator-nightly-2.4.0.dev2020070601 tf-models-nightly-2.2.0.dev20200707 tf-nightly-2.4.0.dev20200706 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QarjD0nF26OQ",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "import pickle\n",
        "import pandas as pd\n",
        "# from bert.tokenization\n",
        "from bert import bert_tokenization\n",
        "import official.nlp.bert.tokenization\n",
        "# from bert.tokenization import FullSentencePieceTokenizer\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Q9XJO_smmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "abf288f1-fa37-4165-d5dc-8c748f313378"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBQLfYoM4jVv",
        "colab": {}
      },
      "source": [
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/albert_en_base/1\",\n",
        "                            trainable=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH8BSLfx8dO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = tfds.load(name=\"civil_comments\", split=[\"train\", \"test\"], data_dir=\"/content/drive/My Drive/AD/civil_comments\", batch_size=-1, as_supervised=True)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU5E5wWX9KUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_examples, train_labels = tfds.as_numpy(train_data)\n",
        "test_examples, test_labels = tfds.as_numpy(test_data)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSCa7pWD6ZfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "more_to_train_negative = pd.read_csv(\"more.csv\")\n",
        "more_to_test_negative = pd.read_csv(\"test_n.csv\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf6WN_986xbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc0ae6e8-d644-4619-f44b-ee087a77ec0a"
      },
      "source": [
        "len( more_to_test_negative.comment_text.to_list() )"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6229"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4ZRoDB56UCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "negative_comments_positions = np.argwhere(train_labels == 1)[:,0]\n",
        "negative_comments = train_examples[negative_comments_positions]\n",
        "negative_comments = np.hstack((negative_comments,  more_to_train_negative.comment_text.to_numpy() ) )\n",
        "\n",
        "\n",
        "negative_comments_positions_test = np.argwhere(test_labels == 1)[:,0]\n",
        "\n",
        "negative_comments_test = test_examples[negative_comments_positions_test]\n",
        "negative_comments_test = np.hstack((negative_comments_test,  more_to_test_negative.comment_text.to_numpy() ) )\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GjcJttBOcT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6ba06033-a08a-4bdb-e813-173d6169f160"
      },
      "source": [
        "\n",
        "not_all_positive_comments_positions = np.argwhere(train_labels == 0)[:negative_comments.shape[0], 0]\n",
        "not_all_positive_comments_positions_test = np.argwhere(test_labels == 0)[:negative_comments_test.shape[0], 0]\n",
        "\n",
        "not_all_positive_comments = train_examples[not_all_positive_comments_positions]\n",
        "not_all_positive_comments_test = test_examples[not_all_positive_comments_positions_test]\n",
        "\n",
        "\n",
        "print( not_all_positive_comments_positions_test.shape)\n",
        "print( not_all_positive_comments_positions.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6451,)\n",
            "(20577,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zWQEZJq9ilO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_T = np.hstack( (np.ones(negative_comments.shape[0]), np.zeros(negative_comments.shape[0]) ) )\n",
        "labels_t = np.hstack( (np.ones(negative_comments_test.shape[0]), np.zeros(negative_comments_test.shape[0]) ) )\n",
        "\n",
        "\n",
        "all_to_train = np.hstack((negative_comments, not_all_positive_comments ))\n",
        "all_to_test = np.hstack(( negative_comments_test, not_all_positive_comments_test))\n",
        "\n",
        "\n",
        "\n",
        "perm_T = np.random.permutation(all_to_train.shape[0])\n",
        "perm_t = np.random.permutation(all_to_test.shape[0])\n",
        "\n",
        "train_examples = all_to_train[perm_T]\n",
        "train_labels = labels_T[perm_T]\n",
        "\n",
        "test_examples = all_to_test[perm_t]\n",
        "test_labels = labels_t[perm_t]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nwyZ1blxnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af114b90-29ba-45cf-d465-5965d31a7176"
      },
      "source": [
        "type (test_examples )"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O2jphuylnzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "more_to_training = 8000\n",
        "\n",
        "\n",
        "train_examples = np.hstack((train_examples, test_examples[:more_to_training] ))\n",
        "train_labels = np.hstack((train_labels, test_labels[:more_to_training] ))\n",
        "\n",
        "test_examples = test_examples[more_to_training:]\n",
        "test_labels = test_labels[more_to_training:]\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYK6x5W2m853",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6605fcf-85d1-4688-b08f-3bb69bea3787"
      },
      "source": [
        "test_examples.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4902,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOL7Ijfl0Xkm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "62da8151-9f10-49f3-9f7c-fb6283664bc4"
      },
      "source": [
        "idx = 41\n",
        "\n",
        "print (test_labels[idx] )\n",
        "print (test_examples[idx])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "b\"That's an odd comment, CanadaRob3, especially given the facts.  However, no odder than 'The media lies - to YOU' liking it and 'disagreeing' with reports of what the judge actually did.  I'll wait for  your responses, shall I?\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4OszTwzI5NN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?official.nlp.bert.tokenization.FullSentencePieceTokenizer"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayE4ECXiF-UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp_model_file = bert_layer.resolved_object.sp_model_file.asset_path.numpy()\n",
        "tokenizer = official.nlp.bert.tokenization.FullSentencePieceTokenizer(sp_model_file)\n",
        "\n",
        "\n",
        "def tokenize_text(txt):\n",
        "    tokenized_txt = tokenizer.tokenize(txt)\n",
        "    tokenized_txt = [\"[CLS]\"] + tokenized_txt + [\"[SEP]\"]\n",
        "    tokenized_txt = tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
        "    return tokenized_txt"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lxbPWJsfaeMz",
        "colab": {}
      },
      "source": [
        "\n",
        "train_examples = list(map(tokenize_text, train_examples))\n",
        "test_examples = list(map(tokenize_text, test_examples))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VaE0a7un4jxo",
        "colab": {}
      },
      "source": [
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(train_examples, maxlen=125, padding='post')\n",
        "max_seq_length = x_train.shape[1]\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(test_examples, maxlen=max_seq_length, padding='post', truncating='post')\n",
        "\n",
        "train_mask = (x_train != 0).astype(int)\n",
        "test_mask = (x_test != 0).astype(int)\n",
        "\n",
        "train_segments = np.zeros(x_train.shape)\n",
        "test_segments = np.zeros(x_test.shape)\n",
        "\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "\n",
        "bert_inputs = [input_word_ids, input_mask, segment_ids]\n",
        "pooled_output, sequence_output = bert_layer(bert_inputs)\n",
        "\n",
        "final_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "final_output = final_layer(pooled_output)\n",
        "# tf.keras.layers.\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JNZiaCMch3cx",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Model(inputs=bert_inputs, outputs=final_output)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SyJVEKY1iAds",
        "colab": {}
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              optimizer=tf.optimizers.Adam(learning_rate=1e-5), \n",
        "              # optimizer=tf.optimizers.Adam(), \n",
        "\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YWyhH8EbiAi9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ecaf9e97-f95e-4c92-dc71-94b540d91ea7"
      },
      "source": [
        "model.fit([x_train, train_mask, train_segments], train_labels, epochs=4, batch_size=32,\n",
        "          validation_data=([x_test, test_mask, test_segments], test_labels))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1537/1537 [==============================] - 2197s 1s/step - loss: 0.1244 - accuracy: 0.9554 - val_loss: 0.1664 - val_accuracy: 0.9396\n",
            "Epoch 2/4\n",
            "1537/1537 [==============================] - 2209s 1s/step - loss: 0.0858 - accuracy: 0.9698 - val_loss: 0.1785 - val_accuracy: 0.9317\n",
            "Epoch 3/4\n",
            "1537/1537 [==============================] - 2210s 1s/step - loss: 0.0604 - accuracy: 0.9795 - val_loss: 0.1628 - val_accuracy: 0.9370\n",
            "Epoch 4/4\n",
            "1537/1537 [==============================] - 2183s 1s/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 0.1792 - val_accuracy: 0.9368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd00fc1a898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dwIibUEq_6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5a1afab3-09d1-484a-81d5-c27b7a50ac36"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "text = pd.read_csv(\"notI.csv\", names=[\"sentance\"], index_col=False)\n",
        "text = text.to_numpy()\n",
        "\n",
        "print (text[:,0].tolist())\n",
        "text = text[:,0].tolist()\n",
        "text = list(map(tokenize_text, text))\n",
        "print(text[0])\n",
        "text = tf.keras.preprocessing.sequence.pad_sequences(text, maxlen=100, padding='post')\n",
        "mask = (text != 0).astype(int)\n",
        "segments = np.zeros(text.shape)\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['temporrytext that is absoulutlely not important', 'anotehre aboulutally not important text', 'you are ugly so ugly', 'hate speech']\n",
            "[2, 14935, 139, 622, 11969, 30, 25, 12178, 111, 8331, 5866, 102, 52, 681, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAdKRrRRE7FK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "98fefea7-a888-40f6-92c8-56dce11f1a6d"
      },
      "source": [
        "model([text, mask, segments])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
              "array([[0.7027308 ],\n",
              "       [0.98811334],\n",
              "       [0.9995449 ],\n",
              "       [0.9718593 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uySMyZoZMOzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGc6J4cJjdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "aed616a5-7904-4fed-e22b-0e79718eba72"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 11683584    input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            769         keras_layer[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 11,684,353\n",
            "Trainable params: 11,684,353\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqCQSKh_qIuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "30a1a5c6-c715-4c39-ecea-78f1b9098a8f"
      },
      "source": [
        "m = tf.keras.models.load_model(\"/content/drive/My Drive/AD/check/my_model\")\n",
        "print (m([text, mask, segments]) )\n",
        "m.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.00341263]\n",
            " [0.00178851]\n",
            " [0.996042  ]\n",
            " [0.89366364]], shape=(4, 1), dtype=float32)\n",
            "Model: \"functional_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 11683584    input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            769         keras_layer[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 11,684,353\n",
            "Trainable params: 11,684,353\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM_M8NX4sOxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resoult = m([text, mask, segments])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxKFV_EqsXep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resoult = resoult > 0.5\n",
        "resoult = np.array(resoult, dtype='int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLPMXjmgsder",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"foo.csv\", resoult, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvKz4CPiYtQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8318a1f1-43be-41e0-ea56-711f88cf785a"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/AD/check/my_model4\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/AD/check/my_model3/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/AD/check/my_model3/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFqG2hoZsxGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}